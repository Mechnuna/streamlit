import streamlit as st
import pandas as pd
import json
import copy
import zipfile
import os
import re
import datetime
###################################

from st_aggrid import AgGrid
from st_aggrid.grid_options_builder import GridOptionsBuilder
from description import desc_alg1, desc_alg2
from st_aggrid import GridUpdateMode, DataReturnMode
###################################

from functionforDownloadButtons import download_button
from crossale_utils import *
from first_algos import ndcg_at, mean_average_precision, mean_reciprocal_rank
from second_algos import ndcg_at_k
from my_algos import my_ndcg
from simlar_utils import similar
###################################
from typing import Dict
from gs import GS
from ns import NS


@st.cache(allow_output_mutation=True)
def get_static_store() -> Dict:
    """–≠—Ç–æ—Ç —Å–ª–æ–≤–∞—Ä—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑ –∏ –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤."""
    return {},{}


def write_logs(algorithm, options, ndcg_result, map_result, mrr_result):
	with open('logs/result','a') as f:
		now = datetime.datetime.now()
		new_text = f"{now} Model:{options} Algorithm {algorithm}\nNDCG:{ndcg_result} MAP:{map_result} MRR:{mrr_result}\n\n"
		f.write(new_text)


def cross_sale(label='name'):
	'''–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏ –ø–æ—Ö–æ–∂–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤'''
	all_db = None
	if st.button("Clear file list and folder json"):
		all_db = None
		os.system('rm -rf json; mkdir json')

	uploaded_file = st.file_uploader("Upload", type=["zip", "csv"], accept_multiple_files=True)

	if uploaded_file:
		for num, files in enumerate(uploaded_file):
			#–µ—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∏–ª–∏ zip –∞—Ä—Ö–∏–≤, —Ç–æ —Ä–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –µ–≥–æ –≤ –ø–∞–ø–∫—É csv
			if files.type == "application/zip":
				with zipfile.ZipFile(files, "r") as z:
					z.extractall("csv/")
					n = 0
					for filename in os.listdir('csv'):
						#—Ä–∞–±–æ—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ —Å —Ñ–∞–π–ª–∞–º–∏ csv
						x = re.search('.csv$', filename)
						if x:
							if n == 0:
								all_db = pd.read_csv('csv/'+filename)
								file_container = st.expander("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–∞—à –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª .csv")
								files.seek(0)
								file_container.write(all_db)
								n += 1
							else:
								shows = pd.read_csv('csv/'+filename)
								file_container = st.expander("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–∞—à –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª .csv")
								all_db = all_db.merge(shows, left_on=label,right_on=label)
								files.seek(0)
								file_container.write(shows)
			#–µ—Å–ª–∏ –ø—Ä–æ—Å—Ç–æ —Ñ–∞–π–ª—ã csv
			else:
				if num == 0:
					all_db = pd.read_csv(uploaded_file[0])
					file_container = st.expander("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–∞—à –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª .csv")
					files.seek(0)
					file_container.write(all_db)
				else:
					file_container = st.expander("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–∞—à –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª .csv")
					shows = pd.read_csv(files)
					all_db = all_db.merge(shows, left_on=label,right_on=label)
					files.seek(0)
					file_container.write(shows)
					

	else:
		st.info(
			f"""
				üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ a .csv —Ñ–∞–π–ª. –ù–∞–ø—Ä–∏–º–µ—Ä: [biostats.csv](https://people.sc.fsu.edu/~jburkardt/data/csv/biostats.csv)
				"""
		)

		st.stop()
	return all_db



def main():
	'''–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è'''
	def _max_width_():
		max_width_str = f"max-width: 1800px;"
		st.markdown(
			f"""
		<style>
		.reportview-container .main .block-container{{
			{max_width_str}
		}}
		</style>    
		""",
			unsafe_allow_html=True,
		)

	st.set_page_config(page_icon="üêà", page_title="CSV Wrangler")

	st.image(
		"https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/325/paw-prints_1f43e.png",
		width=100,
	)

	options = st.radio("–í—ã–±–µ—Ä–∏—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º", ['–ö—Ä–æ—Å—Å-—Å–µ–π–ª', '–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ', '–ü–æ—Ö–æ–∂–∏–µ'], key='algorithm_')
	model_recommendation = {} # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –º–æ–¥–µ–ª–∏
	gold_standart,numbers_gs = get_static_store() # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –∑–æ–ª–æ—Ç–æ–º—É —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É  –∏ –æ—Ü–µ–Ω–æ–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –ø–æ –∑–æ–ª–æ—Ç–æ–º—É —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É
	
	c29, c30, c31 = st.columns([1, 6, 1])

	with c30:
		if options == '–ö—Ä–æ—Å—Å-—Å–µ–π–ª':
			crosale_checkbox = st.radio("–í—ã–±–µ—Ä–∏—Ç–µ csv —Ñ–∞–π–ª", ['–õ–µ—Å–∫–∏ 90', '–õ–µ—Å–∫–∏ —Ä–∞–∑–Ω—ã–µ', '–¢—Ä–∏–º–º–µ—Ä—ã –ù–æ–≤—ã–π –∫–∞—Ç–∞–ª–æ–≥'])
			match crosale_checkbox:
				case '–õ–µ—Å–∫–∏ 90':
					file_csv = 'csv/Crosssale90.csv'
				case '–õ–µ—Å–∫–∏ —Ä–∞–∑–Ω—ã–µ':
					file_csv = 'csv/Crosssale.csv'
				case '–¢—Ä–∏–º–º–µ—Ä—ã –ù–æ–≤—ã–π –∫–∞—Ç–∞–ª–æ–≥':
					file_csv = 'csv/Crosssale50trimmer.csv'
			new_data = pd.read_csv(file_csv, index_col='name')
			label = 'name'
		elif options == '–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ':
			new_data = pd.read_csv('csv/Alternative.csv', index_col='name')
			label = 'name'
		elif options == '–ü–æ—Ö–æ–∂–∏–µ':
			gold_standart, numbers_gs = GS, NS

	if options != '–ü–æ—Ö–æ–∂–∏–µ':

			all_trimmer = new_data.index #url –≤—Å–µ—Ö —Ç—Ä–∏–º–º–µ—Ä–æ–≤
			all_rec = list(new_data.columns)[1:] #–Ω–∞–∑–≤–∞–Ω–∏—è –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –∫—Ä–æ—Å—Å-—Å–µ–π–ª–∞

			#–∑–∞–ø—É—Å–∫–∞–µ–º —Ü–∏–∫–ª –ø–æ –î–∞—Ç–∞–§—Ä–µ–π–º—É
			for url in all_trimmer:
				gold_standart_pair = {}
				numbers_gs_mass = []

				one_line = new_data.loc[url]
				for name_rec in all_rec:
					gold_standart_pair[name_rec.strip()]=new_data[name_rec][url]/100 # –ó–∞—Å–æ–≤—ã–≤–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –≤ —Å–ª–æ–≤–∞—Ä—å
					numbers_gs_mass.append(new_data[name_rec][url]/100)

				offer_id = return_id(url) # –≤—ã—Ä–µ–∑–∞–µ–º offer_id –∏–∑ —Å—Å—ã–ª–∫–∏ 
				numbers_gs_mass.sort(reverse=True) # —Å–æ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é
				gold_standart[offer_id] = gold_standart_pair # –ó–∞—Å–æ–≤—ã–≤–∞–µ–º –ø–æ offer_id —Å–ª–æ–≤–∞—Ä—å —Å –æ—Ü–µ–Ω–∫–æ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Ç–æ–≤–∞—Ä–æ–≤
				numbers_gs[offer_id] = numbers_gs_mass
	#–ó–∞–≥—Ä—É–∂–∞–µ–º JSON —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–µ–π –æ—Ç –º–æ–¥–µ–ª–∏ –∏ –ø–∞—Ä—Å–∏–º –µ–≥–æ

	st.text("")
	st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ JSON")

	rec = None
	offers = None
	json_file = st.file_uploader(
			"",
			key="json",
			type=["zip", "json", "csv"], 
			accept_multiple_files=True
		)
	json_flag = 0

	if json_file:
		for file_rec in json_file:
			if len(json_file) == 1:
				if file_rec.type == "application/zip":
					with zipfile.ZipFile(file_rec, "r") as z:
							z.extractall("json/")
							zipname = file_rec.name.strip('.zip')
							dir_name = 'json/'
							for filename in os.listdir(dir_name):
								if filename == 'rec.csv':
									json_flag = 2
									rec = pd.read_csv(dir_name + '/rec.csv')
								elif filename == 'offers.csv':
									offers = pd.read_csv(dir_name + '/offers.csv',index_col="OFFERID")
				elif file_rec.type == "application/json":
					json_flag = 1
					js = json.load(file_rec)
			else:
				if file_rec.name == 'rec.csv':
					json_flag = 2
					rec = pd.read_csv(file_rec)
				elif file_rec.name == 'offers.csv':
					offers = pd.read_csv(file_rec,index_col="OFFERID")

	else:
		st.info(
			f"""
				üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–∞—Ç–∞–ª–æ–≥ —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ json –∏–ª–∏ zip —Å —Ñ–∞–π–ª–∞–º–∏ csv
				"""
		)
		st.stop()
	if json_flag == 1:
		json_elem = js["recommendations"]
		# –ù–∞—Ö–æ–¥–∏–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–æ–≤–∞—Ä–∞
		for elem in json_elem:
			model_recommendation_mass = []
			url_json_elem = return_id(elem['urlLink'])
			mass_rec_id = elem["recommendItems"]
			
			for offer_id in mass_rec_id:
				if options == '–ü–æ—Ö–æ–∂–∏–µ':
					model_recommendation_mass.append(return_id(offer_id['urlLink']))
				else:
					model_recommendation_mass.append(offer_id['name'])
			model_recommendation[url_json_elem] = model_recommendation_mass

	j = []
	if json_flag == 2:
		for i in rec.index:
			name = rec.iloc[i]['SOMEID']
			id_product = return_id(offers.loc[name]['URL'])
			if gold_standart.get(id_product):
				name2 = rec.iloc[i]['RECOMMENDATIONOFFERID']
				if options == '–ü–æ—Ö–æ–∂–∏–µ':
					try:
						model_recommendation[id_product].append(str(int(name2)))
					except:
						print("MAKE", id_product)
						model_recommendation[id_product] = []
						model_recommendation[id_product].append(str(int(name2)))
				else:
					try:
						model_recommendation[id_product].append(offers.loc[name2]['NAME'].strip())
					except:
						j.append(id_product)
						model_recommendation[id_product] = []
						model_recommendation[id_product].append(offers.loc[name2]['NAME'].strip())
	#–í—ã–¥–∞–µ–º –≤—Å–µ–º —Ç–æ–≤–∞—Ä–∞–º –∏–∑ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ JSON –æ—Ü–µ–Ω–∫—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏–∑ –ó–æ–ª–æ—Ç–æ–≥–æ –°—Ç–∞–Ω–¥–∞—Ä—Ç–∞
	metrics = {} # —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ü–µ–Ω–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∫ –∫–∞–∂–¥–æ–º—É —Ç–æ–≤–∞—Ä—É 
	metrics_name = {} # —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤

	for offer_id, rec_mass in model_recommendation.items():
		metrics_dic = []
		names = []
		for product in rec_mass:
				try:
					metrics_dic.append(gold_standart[offer_id][product])
					names.append(product)
				except:
					pass
		if metrics_dic:
			metrics[offer_id] = metrics_dic
		else:
			print(offer_id)
		if names:
			metrics_name[offer_id] = names

	but3, but4, _  = st.columns(3)

	with but3:
		show_rec = st.button("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
	with but4:
		hide_rec = st.button("–°–∫—Ä—ã—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
	#–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞–≥–ª—è–¥–Ω–æ —á—Ç–æ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ –∑–æ–ª–æ—Ç–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç
	if show_rec:
		st.markdown('<h2 style="font-size:24px;">–¢–û–ü 10 –¢–û–í–ê–†–û–í –î–õ–Ø –¢–†–ò–ú–ú–ï–†–ê</h2>', unsafe_allow_html=True)
		new_metrics, name_gs = print_top5(metrics, metrics_name, gold_standart)

	new_metrics, name_gs = print_top5(metrics, metrics_name, gold_standart, print_=False)

	windows = st.number_input("–ó–∞–¥–∞—Ç—å –æ–∫–æ—à–∫–æ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏", key="win1_r",value=6,step=1,
	help="–û–∫–æ—à–∫–æ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ - –¥–æ–ø—É—Å—Ç–∏–º–∞—è –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å –≤ –ø–æ—Ä—è–¥–∫–µ —Ç–æ–≤–∞—Ä–∞ –≤ –ª–µ–Ω—Ç–µ. –ù–∞–ø—Ä–∏–º–µ—Ä: \n\
		[1,3,4,5,6,7] –ø—Ä–∏ –æ–∫–æ—à–∫–µ 3 —Ç–æ–≤–∞—Ä –ø–æ–¥ –Ω–æ–º–µ—Ä–æ–º 4 –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–∞ 2,3,4 –º–µ—Å—Ç–∞—Ö")
	options2 = st.radio("–í—ã–±–µ—Ä–∏—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º", ['1', '2'], key='algorithm_radio')
	windows //= 2
	go_button = st.button('–ü–æ–¥—Å—á–∏—Ç–∞—Ç—å')

	if go_button:
		if options2 == '1':

			st.markdown("# –°–ø–æ—Å–æ–± –ø–µ—Ä–≤—ã–π")
			st.markdown(desc_alg1,unsafe_allow_html=True)

			ans1, ans2 = st.columns(2)

			with ans1:
				final_gold_standart, final_model_rec = valid_product_value(metrics, numbers_gs, copy.deepcopy(metrics), windows)
				with open ('final_gold_standart.txt', 'w') as f:
					f.write(str(final_gold_standart))
				with open ('final_model_rec.txt', 'w') as f:
					f.write(str(final_model_rec))
				expan_r = st.expander("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å DCG, MAX DCG")
				with expan_r:
					result_2 = ndcg_at(final_model_rec, final_gold_standart)
				map_result = mean_average_precision(final_model_rec, final_gold_standart)
				mrr_result = mean_reciprocal_rank(final_gold_standart)
				st.write("C—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –∑–Ω–∞—á–µ–Ω–∏—è–º")
				st.write("NDCG:",result_2)
				st.write("MAP:",map_result)	
				st.write("MRR:",mrr_result)

				if result_2 >= 0.4:
					st.markdown("### –í–°–ï –•–û–†–û–®–û")
				else:
					st.markdown("### –ë–´–õ–û –ü–û–õ–£–ß–®–ï")
				write_logs(1, options, result_2, map_result, mrr_result)


				


		elif options2 == '2':

			st.markdown("# –°–ø–æ—Å–æ–± –≤—Ç–æ—Ä–æ–π")
			st.markdown(desc_alg2,unsafe_allow_html=True)

			ans1, ans2 = st.columns(2)

			with ans1:
				final_model_rec = []
				final_gold_standart = []
				for offer_id in new_metrics:
					final_model_rec.append(metrics[offer_id])
					final_gold_standart.append(numbers_gs[offer_id])
		
				final = my_ndcg(final_model_rec, final_gold_standart)
				st.write("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏–∑ –ó–æ–ª–æ—Ç–æ–≥–æ –°—Ç–∞–Ω–¥–∞—Ä—Ç–∞")
				st.write('NDCG',final)

				if final >= 0.4:
					st.markdown("### –í–°–ï –•–û–†–û–®–û")
				else:
					st.markdown("### –ë–´–õ–û –ü–û–õ–£–ß–®–ï")
				write_logs(2, options, final, None, None)


if __name__ == '__main__':
	try:
		main()
	finally:
		os.system('rm -rf json; mkdir json')
		print("RESTART")