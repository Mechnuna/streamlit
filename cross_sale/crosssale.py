import streamlit as st
import pandas as pd
import json
import copy
###################################

from st_aggrid import AgGrid
from st_aggrid.grid_options_builder import GridOptionsBuilder
from description import desc_alg1, desc_alg2
###################################

from functionforDownloadButtons import download_button
from crossale_utils import *
from first_algos import ndcg_at, mean_average_precision, mean_reciprocal_rank
from second_algos import ndcg_at_k, map_mass, mrr

###################################


def main():

	def _max_width_():
		max_width_str = f"max-width: 1800px;"
		st.markdown(
			f"""
		<style>
		.reportview-container .main .block-container{{
			{max_width_str}
		}}
		</style>    
		""",
			unsafe_allow_html=True,
		)

	st.set_page_config(page_icon="üêà", page_title="CSV Wrangler")

	st.image(
		"https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/325/paw-prints_1f43e.png",
		width=100,
	)

	c29, c30, c31 = st.columns([1, 6, 1])

	with c30:

		number = st.slider('–°–∫–æ–ª—å–∫–æ –¥–∞—Ç–∞ —Ñ—Ä–µ–π–º–æ–≤ –Ω—É–∂–Ω–æ —Å–∫–ª–µ–∏—Ç—å?',1,5,key='database_count')
		all_db = None

		uploaded_file = st.file_uploader(
			"",
			key="1",
			help="To activate 'wide mode', go to the hamburger menu > Settings > turn on 'wide mode'",
		)

		if uploaded_file is not None:
			file_container = st.expander("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–∞—à –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª .csv")
			all_db = pd.read_csv(uploaded_file)
			uploaded_file.seek(0)
			file_container.write(all_db)
			if st.session_state['database_count'] != 1:

				for i in range(st.session_state['database_count'] - 1):
					uploaded_file = st.file_uploader(
						"",
						key=str(i+2),
					)

					if uploaded_file is not None:
						file_container = st.expander("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–∞—à –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª .csv")
						shows = pd.read_csv(uploaded_file,index_col='name')
						all_db = all_db.merge(shows, left_on="name",right_on="name")
						uploaded_file.seek(0)
						file_container.write(shows)
					else:
						st.stop()

		else:
			st.info(
				f"""
					üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ a .csv —Ñ–∞–π–ª. –ù–∞–ø—Ä–∏–º–µ—Ä: [biostats.csv](https://people.sc.fsu.edu/~jburkardt/data/csv/biostats.csv)
					"""
			)

			st.stop()

	from st_aggrid import GridUpdateMode, DataReturnMode

	gb = GridOptionsBuilder.from_dataframe(all_db)

	gb.configure_default_column()
	gb.configure_selection(selection_mode="multiple", use_checkbox=True)
	gb.configure_side_bar()
	gridOptions = gb.build()

	st.success(
		f"""
			üí° –ü–æ–¥—Å–∫–∞–∑–∫–∞! –£–¥–µ—Ä–∂–∏–≤–∞–π—Ç–µ shift —á—Ç–æ–±—ã –≤—ã–±—Ä–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫!
			"""
	)

	response = AgGrid(
		all_db,
		gridOptions=gridOptions,
		enable_enterprise_modules=True,
		update_mode=GridUpdateMode.MODEL_CHANGED,
		data_return_mode=DataReturnMode.FILTERED_AND_SORTED,
		fit_columns_on_grid_load=False,
	)



	df = pd.DataFrame(response["selected_rows"])

	try:
		df = df.set_index('name')
	except:
		st.write("–í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ç–æ–≤–∞—Ä")

	st.subheader("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç üëá ")
	st.text("")

	but1, but2, _ = st.columns(3)

	with but1:
		show_table = st.button("–ü–æ–∫–∞–∑–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É")
	with but2:
		hide_table = st.button("–°–∫—Ä—ã—Ç—å —Ç–∞–±–ª–∏—Ü—É")

	if show_table:
		st.table(df)

		c29, c30, c31 = st.columns([1, 1, 2])

		with c29:

			CSVButton = download_button(
				df,
				"File.csv",
				"Download to CSV",
			)

		with c30:
			CSVButton = download_button(
				df,
				"File.csv",
				"Download to TXT",
			)
		st.stop()



	st.text("")

	st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ JSON")

	json_file = st.file_uploader(
			"",
			key="json",
		)

	if json_file is not None:
		js = json.load(json_file)

	else:
		st.info(
			f"""
				üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–∞—Ç–∞–ª–æ–≥ —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ json
				"""
		)

		st.stop()

	model_recommendation = {} # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –º–æ–¥–µ–ª–∏
	gold_standart = {} # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –∑–æ–ª–æ—Ç–æ–º—É —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É
	numbers_gs = {} # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ –æ—Ü–µ–Ω–æ–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –ø–æ –∑–æ–ª–æ—Ç–æ–º—É —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É

	new_data = df

	all_trimmer = new_data.index #url –≤—Å–µ—Ö —Ç—Ä–∏–º–º–µ—Ä–æ–≤
	all_rec = new_data.columns #–Ω–∞–∑–≤–∞–Ω–∏—è –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –∫—Ä–æ—Å—Å-—Å–µ–π–ª–∞

	#–∑–∞–ø—É—Å–∫–∞–µ–º —Ü–∏–∫–ª –ø–æ –î–∞—Ç–∞–§—Ä–µ–π–º—É
	for url in all_trimmer:
		gold_standart_pair = {}
		numbers_gs_mass = []

		one_line = new_data.loc[url]
		for name_rec in all_rec:
			gold_standart_pair[name_rec.strip()]=new_data[name_rec][url]/100 # –ó–∞—Å–æ–≤—ã–≤–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –≤ —Å–ª–æ–≤–∞—Ä—å
			numbers_gs_mass.append(new_data[name_rec][url]/100)

		offer_id = return_id(url) # –≤—ã—Ä–µ–∑–∞–µ–º offer_id –∏–∑ —Å—Å—ã–ª–∫–∏ 
		numbers_gs_mass.sort(reverse=True) # —Å–æ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é
		gold_standart[offer_id] = gold_standart_pair # –ó–∞—Å–æ–≤—ã–≤–∞–µ–º –ø–æ offer_id —Å–ª–æ–≤–∞—Ä—å —Å –æ—Ü–µ–Ω–∫–æ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Ç–æ–≤–∞—Ä–æ–≤
		numbers_gs[offer_id] = numbers_gs_mass

	json_elem = js["recommendations"]
	# –ù–∞—Ö–æ–¥–∏–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–æ–≤–∞—Ä–∞
	for elem in json_elem:
		model_recommendation_mass = []
		url_json_elem = return_id(elem['urlLink'])
		mass_rec_id = elem["recommendItems"]
		
		for offer_id in mass_rec_id:
			model_recommendation_mass.append(offer_id['name'])
		model_recommendation[url_json_elem] = model_recommendation_mass

	#–í—ã–¥–∞–µ–º –≤—Å–µ–º —Ç–æ–≤–∞—Ä–∞–º –∏–∑ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ JSON –æ—Ü–µ–Ω–∫—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏–∑ –ó–æ–ª–æ—Ç–æ–≥–æ –°—Ç–∞–Ω–¥–∞—Ä—Ç–∞
	metrics = {} # —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ü–µ–Ω–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∫ –∫–∞–∂–¥–æ–º—É —Ç–æ–≤–∞—Ä—É 
	metrics_name = {} # —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤

	for offer_id, rec_mass in model_recommendation.items():
		metrics_dic = []
		names = []
		for product in rec_mass:
				zz = 0
				try:
					metrics_dic.append(gold_standart[offer_id][product])
					names.append(product)
				except:
					q = 0
		if metrics_dic:
			metrics[offer_id] = metrics_dic
		if names:
			metrics_name[offer_id] = names

	but3, but4, _  = st.columns(3)

	with but3:
		show_rec = st.button("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
	with but4:
		hide_rec = st.button("–°–∫—Ä—ã—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")


	#–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞–≥–ª—è–¥–Ω–æ —á—Ç–æ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ –∑–æ–ª–æ—Ç–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç
	if show_rec:
		st.markdown('<h2 style="font-size:24px;">–¢–û–ü 10 –¢–û–í–ê–†–û–í –î–õ–Ø –¢–†–ò–ú–ú–ï–†–ê</h2>', unsafe_allow_html=True)
		new_metrics, name_gs = print_top5(metrics, metrics_name, gold_standart)

	new_metrics, name_gs = print_top5(metrics, metrics_name, gold_standart, print_=False)


	windows = st.number_input("–ó–∞–¥–∞—Ç—å –æ–∫–æ—à–∫–æ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏", key="win1_r",value=3,step=1,
	help="–û–∫–æ—à–∫–æ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ - –¥–æ–ø—É—Å—Ç–∏–º–∞—è –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å –≤ –ø–æ—Ä—è–¥–∫–µ —Ç–æ–≤–∞—Ä–∞ –≤ –ª–µ–Ω—Ç–µ. –ù–∞–ø—Ä–∏–º–µ—Ä: \n\
		[1,3,4,5,6,7] –ø—Ä–∏ –æ–∫–æ—à–∫–µ 3 —Ç–æ–≤–∞—Ä –ø–æ–¥ –Ω–æ–º–µ—Ä–æ–º 4 –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–∞ 2,3,4 –º–µ—Å—Ç–∞—Ö")
	options = st.radio("–í—ã–±–µ—Ä–∏—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º", ['1', '2'], key='algorithm_radio')
	windows //= 2
	go_button = st.button('–ü–æ–¥—Å—á–∏—Ç–∞—Ç—å')

	if go_button:

		if options == '1':

			st.markdown("# –°–ø–æ—Å–æ–± –ø–µ—Ä–≤—ã–π")
			st.markdown(desc_alg1,unsafe_allow_html=True)

			ans1, ans2 = st.columns(2)

			with ans1:
				final_gold_standart, final_model_rec = valid_product_value(metrics, numbers_gs, copy.deepcopy(metrics), windows)
				expan_r = st.expander("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å DCG, MAX DCG")
				with expan_r:
					result_2 = ndcg_at(final_model_rec, final_gold_standart)
				st.write("C—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –∑–Ω–∞—á–µ–Ω–∏—è–º")
				st.write("NDCG:",result_2)
				st.write("MAP:",mean_average_precision(final_model_rec, final_gold_standart))	
				st.write("MRR:",mean_reciprocal_rank(final_gold_standart))

				if result_2 >= 0.4:
					st.markdown("### –í–°–ï –•–û–†–û–®–û")
				else:
					st.markdown("### –ë–´–õ–û –ü–û–õ–£–ß–®–ï")

		elif options == '2':

			st.markdown("# –°–ø–æ—Å–æ–± –≤—Ç–æ—Ä–æ–π")
			st.markdown(desc_alg2,unsafe_allow_html=True)

			ans1, ans2 = st.columns(2)

			with ans1:
				final_model_rec = []
				final_gold_standart = []
				for offer_id in new_metrics:
					final_model_rec.append(metrics[offer_id])
					final_gold_standart.append(numbers_gs[offer_id])

				sums = 0
				expan_l = st.expander("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å DCG, MAX DCG")
				with expan_l:
					for i in range(len(final_model_rec)):
						l = ndcg_at_k(final_model_rec[i], final_gold_standart[i], 10, 1)
						sums += l
				st.write("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏–∑ –ó–æ–ª–æ—Ç–æ–≥–æ –°—Ç–∞–Ω–¥–∞—Ä—Ç–∞")
				final = sums/len(final_model_rec)
				st.write('NDCG',final)

				if final >= 0.4:
					st.markdown("### –í–°–ï –•–û–†–û–®–û")
				else:
					st.markdown("### –ë–´–õ–û –ü–û–õ–£–ß–®–ï")


if __name__ == '__main__':
	main()