import streamlit as st
import pandas as pd
import json
import copy
import zipfile
import os
import re
import datetime
###################################

from st_aggrid import AgGrid
from st_aggrid.grid_options_builder import GridOptionsBuilder
from description import desc_alg1, desc_alg2
from st_aggrid import GridUpdateMode, DataReturnMode
###################################

from functionforDownloadButtons import download_button
from crossale_utils import *
from first_algos import ndcg_at, mean_average_precision, mean_reciprocal_rank
from second_algos import ndcg_at_k
from simlar_utils import similar
from my_algos import my_ndcg
###################################
from typing import Dict, final


@st.cache(allow_output_mutation=True)
def get_static_store() -> Dict:
    """–≠—Ç–æ—Ç —Å–ª–æ–≤–∞—Ä—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –æ–¥–∏–Ω —Ä–∞–∑ –∏ –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤."""
    return {},{}

def cross_sale(label='name'):
	'''–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –º–æ–¥–µ–ª–∏ –ø–æ—Ö–æ–∂–∏—Ö —Ç–æ–≤–∞—Ä–æ–≤'''
	all_db = None
	if st.button("Clear file list"):
		all_db = None
		os.system('cd csv;rm -rf *')

	uploaded_file = st.file_uploader("Upload", type=["zip", "csv"], accept_multiple_files=True)

	if uploaded_file:
		for num, files in enumerate(uploaded_file):
			#–µ—Å–ª–∏ –∑–∞–≥—Ä—É–∑–∏–ª–∏ zip –∞—Ä—Ö–∏–≤, —Ç–æ —Ä–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º –µ–≥–æ –≤ –ø–∞–ø–∫—É csv
			if files.type == "application/zip":
				with zipfile.ZipFile(files, "r") as z:
					z.extractall("csv/")
					n = 0
					for filename in os.listdir('csv'):
						#—Ä–∞–±–æ—Ç–∞–µ–º —Ç–æ–ª—å–∫–æ —Å —Ñ–∞–π–ª–∞–º–∏ csv
						x = re.search('.csv$', filename)
						if x:
							if n == 0:
								all_db = pd.read_csv('csv/'+filename)
								file_container = st.expander("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–∞—à –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª .csv")
								files.seek(0)
								file_container.write(all_db)
								n += 1
							else:
								shows = pd.read_csv('csv/'+filename)
								file_container = st.expander("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–∞—à –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª .csv")
								all_db = all_db.merge(shows, left_on=label,right_on=label)
								files.seek(0)
								file_container.write(shows)
			#–µ—Å–ª–∏ –ø—Ä–æ—Å—Ç–æ —Ñ–∞–π–ª—ã csv
			else:
				if num == 0:
					all_db = pd.read_csv(uploaded_file[0])
					file_container = st.expander("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–∞—à –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª .csv")
					files.seek(0)
					file_container.write(all_db)
				else:
					file_container = st.expander("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–∞—à –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª .csv")
					shows = pd.read_csv(files)
					all_db = all_db.merge(shows, left_on=label,right_on=label)
					files.seek(0)
					file_container.write(shows)
					

	else:
		st.info(
			f"""
				üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ a .csv —Ñ–∞–π–ª. –ù–∞–ø—Ä–∏–º–µ—Ä: [biostats.csv](https://people.sc.fsu.edu/~jburkardt/data/csv/biostats.csv)
				"""
		)

		st.stop()
	return all_db



def main():
	'''–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è'''
	def _max_width_():
		max_width_str = f"max-width: 1800px;"
		st.markdown(
			f"""
		<style>
		.reportview-container .main .block-container{{
			{max_width_str}
		}}
		</style>    
		""",
			unsafe_allow_html=True,
		)

	st.set_page_config(page_icon="üêà", page_title="CSV Wrangler")

	st.image(
		"https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/120/apple/325/paw-prints_1f43e.png",
		width=100,
	)

	options = st.radio("–í—ã–±–µ—Ä–∏—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º", ['–ö—Ä–æ—Å—Å-—Å–µ–π–ª/–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ', '–ü–æ—Ö–æ–∂–∏–µ'], key='algorithm_')
	
	model_recommendation = {} # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –º–æ–¥–µ–ª–∏
	gold_standart,numbers_gs = get_static_store() # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –∑–æ–ª–æ—Ç–æ–º—É —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É  –∏ –æ—Ü–µ–Ω–æ–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –ø–æ –∑–æ–ª–æ—Ç–æ–º—É —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É
	
	c29, c30, c31 = st.columns([1, 6, 1])

	with c30:
		if options == '–ö—Ä–æ—Å—Å-—Å–µ–π–ª/–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ':
			all_db = cross_sale()
			label = 'name'
		elif options == '–ü–æ—Ö–æ–∂–∏–µ':
			gold_standart, numbers_gs = similar(gold_standart, numbers_gs)

	if options == '–ö—Ä–æ—Å—Å-—Å–µ–π–ª/–ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ':

		gb = GridOptionsBuilder.from_dataframe(all_db)

		gb.configure_default_column()
		gb.configure_selection(selection_mode="multiple", use_checkbox=True)
		gb.configure_side_bar()
		gridOptions = gb.build()

		st.success(
			f"""
				üí° –ü–æ–¥—Å–∫–∞–∑–∫–∞! –£–¥–µ—Ä–∂–∏–≤–∞–π—Ç–µ shift —á—Ç–æ–±—ã –≤—ã–±—Ä–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫!
				"""
		)

		response = AgGrid(
			all_db,
			gridOptions=gridOptions,
			enable_enterprise_modules=True,
			update_mode=GridUpdateMode.MODEL_CHANGED,
			data_return_mode=DataReturnMode.FILTERED_AND_SORTED,
			fit_columns_on_grid_load=False,
		)

		df = pd.DataFrame(response["selected_rows"])

		try:
			df = df.set_index(label)
		except:
			st.write("–í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ç–æ–≤–∞—Ä")

		st.subheader("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç üëá ")
		st.text("")

		but1, but2, _ = st.columns(3)

		with but1:
			show_table = st.button("–ü–æ–∫–∞–∑–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É")
		with but2:
			hide_table = st.button("–°–∫—Ä—ã—Ç—å —Ç–∞–±–ª–∏—Ü—É")

		if show_table:
			st.table(df)

			c29, c30, c31 = st.columns([1, 1, 2])

			with c29:

				CSVButton = download_button(
					df,
					"File.csv",
					"Download to CSV",
				)

			with c30:
				CSVButton = download_button(
					df,
					"File.csv",
					"Download to TXT",
				)
			st.stop()
		new_data = df

		all_trimmer = new_data.index #url –≤—Å–µ—Ö —Ç—Ä–∏–º–º–µ—Ä–æ–≤
		all_rec = new_data.columns #–Ω–∞–∑–≤–∞–Ω–∏—è –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –∫—Ä–æ—Å—Å-—Å–µ–π–ª–∞

		#–∑–∞–ø—É—Å–∫–∞–µ–º —Ü–∏–∫–ª –ø–æ –î–∞—Ç–∞–§—Ä–µ–π–º—É
		for url in all_trimmer:
			gold_standart_pair = {}
			numbers_gs_mass = []

			one_line = new_data.loc[url]
			for name_rec in all_rec:
				gold_standart_pair[name_rec.strip()]=new_data[name_rec][url]/100 # –ó–∞—Å–æ–≤—ã–≤–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –≤ —Å–ª–æ–≤–∞—Ä—å
				numbers_gs_mass.append(new_data[name_rec][url]/100)

			offer_id = return_id(url) # –≤—ã—Ä–µ–∑–∞–µ–º offer_id –∏–∑ —Å—Å—ã–ª–∫–∏ 
			numbers_gs_mass.sort(reverse=True) # —Å–æ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é
			gold_standart[offer_id] = gold_standart_pair # –ó–∞—Å–æ–≤—ã–≤–∞–µ–º –ø–æ offer_id —Å–ª–æ–≤–∞—Ä—å —Å –æ—Ü–µ–Ω–∫–æ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Ç–æ–≤–∞—Ä–æ–≤
			numbers_gs[offer_id] = numbers_gs_mass


	'''–ó–∞–≥—Ä—É–∂–∞–µ–º JSON —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–µ–π –æ—Ç –º–æ–¥–µ–ª–∏ –∏ –ø–∞—Ä—Å–∏–º –µ–≥–æ'''

	st.text("")
	st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ JSON")
	rec = None
	offers = None
	json_file = st.file_uploader(
			"",
			key="json",
			type=["zip", "json", "csv"], 
			accept_multiple_files=True
		)
	json_flag = 0
	#Typeapplication/json
	if json_file:
		for file_rec in json_file:
			if len(json_file) == 1:
				if file_rec.type == "application/zip":
					with zipfile.ZipFile(file_rec, "r") as z:
							z.extractall("json/")
							dir_name = 'json'
							for filename in os.listdir(dir_name):
								if filename == 'rec.csv':
									json_flag = 2
									rec = pd.read_csv(dir_name + '/rec.csv')
								elif filename == 'offers.csv':
									offers = pd.read_csv(dir_name + '/offers.csv',index_col="OFFERID")
				elif file_rec.type == "application/json":
					json_flag = 1
					js = json.load(file_rec)
				else:
					print(file_rec.type)
			else:
				if file_rec.name == 'rec.csv':
					json_flag = 2
					rec = pd.read_csv(file_rec)
				elif file_rec.name == 'offers.csv':
					offers = pd.read_csv(file_rec,index_col="OFFERID")

	else:
		st.info(
			f"""
				üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–∞—Ç–∞–ª–æ–≥ —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ json –∏–ª–∏ zip —Å —Ñ–∞–π–ª–∞–º–∏ csv
				"""
		)
		st.stop()
	
	if json_flag == 2:
		for i in rec.index:
			name = rec.iloc[i]['SOMEID']
			id_product = return_id(offers.loc[name]['URL'])
			name2 = rec.iloc[i]['RECOMMENDATIONOFFERID']
			if options == '–ü–æ—Ö–æ–∂–∏–µ':
				try:
					model_recommendation[id_product].append(str(int(name2)))
				except:
					model_recommendation[id_product] = []
					model_recommendation[id_product].append(str(int(name2)))
			else:
				try:
					model_recommendation[id_product].append(offers.loc[name2]['NAME'].strip())
				except:
					model_recommendation[id_product] = []
					model_recommendation[id_product].append(offers.loc[name2]['NAME'].strip())
	
	if json_flag == 1:
		json_elem = js["recommendations"]
		# –ù–∞—Ö–æ–¥–∏–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–æ–≤–∞—Ä–∞
		for elem in json_elem:
			model_recommendation_mass = []
			url_json_elem = return_id(elem['urlLink'])
			mass_rec_id = elem["recommendItems"]
			
			for offer_id in mass_rec_id:
				if options == '–ü–æ—Ö–æ–∂–∏–µ':
					model_recommendation_mass.append(return_id(offer_id['urlLink']))
				else:
					model_recommendation_mass.append(offer_id['name'])
			model_recommendation[url_json_elem] = model_recommendation_mass
	
	if options == '–ü–æ—Ö–æ–∂–∏–µ':
		show_mass = st.radio("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –ø–æ–ª—É—á–∏–≤—à–∏–π—Å—è –º–∞—Å—Å–∏–≤?", ['–ù–µ—Ç', '–î–∞'], key='yes_no2')
		if show_mass == '–î–∞':
			st.write(model_recommendation)

	#–í—ã–¥–∞–µ–º –≤—Å–µ–º —Ç–æ–≤–∞—Ä–∞–º –∏–∑ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ JSON –æ—Ü–µ–Ω–∫—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏–∑ –ó–æ–ª–æ—Ç–æ–≥–æ –°—Ç–∞–Ω–¥–∞—Ä—Ç–∞
	metrics = {} # —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ü–µ–Ω–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∫ –∫–∞–∂–¥–æ–º—É —Ç–æ–≤–∞—Ä—É 
	metrics_name = {} # —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤

	for offer_id, rec_mass in model_recommendation.items():
		metrics_dic = []
		names = []
		for product in rec_mass:
				try:
					metrics_dic.append(gold_standart[offer_id][product])
					names.append(product)
				except:
					pass
		if metrics_dic:
			metrics[offer_id] = metrics_dic
		if names:
			metrics_name[offer_id] = names

	but3, but4, _  = st.columns(3)

	with but3:
		show_rec = st.button("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
	with but4:
		hide_rec = st.button("–°–∫—Ä—ã—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")


	#–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞–≥–ª—è–¥–Ω–æ —á—Ç–æ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ –∑–æ–ª–æ—Ç–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç
	if show_rec:
		st.markdown('<h2 style="font-size:24px;">–¢–û–ü 10 –¢–û–í–ê–†–û–í –î–õ–Ø –¢–†–ò–ú–ú–ï–†–ê</h2>', unsafe_allow_html=True)
		new_metrics, name_gs = print_top5(metrics, metrics_name, gold_standart)

	new_metrics, name_gs = print_top5(metrics, metrics_name, gold_standart, print_=False)


	windows = st.number_input("–ó–∞–¥–∞—Ç—å –æ–∫–æ—à–∫–æ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏", key="win1_r",value=6,step=1,
	help="–û–∫–æ—à–∫–æ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ - –¥–æ–ø—É—Å—Ç–∏–º–∞—è –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å –≤ –ø–æ—Ä—è–¥–∫–µ —Ç–æ–≤–∞—Ä–∞ –≤ –ª–µ–Ω—Ç–µ. –ù–∞–ø—Ä–∏–º–µ—Ä: \n\
		[1,3,4,5,6,7] –ø—Ä–∏ –æ–∫–æ—à–∫–µ 3 —Ç–æ–≤–∞—Ä –ø–æ–¥ –Ω–æ–º–µ—Ä–æ–º 4 –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–∞ 2,3,4 –º–µ—Å—Ç–∞—Ö")
	options = st.radio("–í—ã–±–µ—Ä–∏—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º", ['1', '2'], key='algorithm_radio')
	windows //= 2
	go_button = st.button('–ü–æ–¥—Å—á–∏—Ç–∞—Ç—å')

	if go_button:

		if options == '1':

			st.markdown("# –°–ø–æ—Å–æ–± –ø–µ—Ä–≤—ã–π")
			st.markdown(desc_alg1,unsafe_allow_html=True)

			ans1, ans2 = st.columns(2)

			with ans1:
				final_gold_standart, final_model_rec = valid_product_value(metrics, numbers_gs, copy.deepcopy(metrics), windows)
				expan_r = st.expander("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å DCG, MAX DCG")
				with expan_r:
					result_2 = ndcg_at(final_model_rec, final_gold_standart)
				st.write("C—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –∑–Ω–∞—á–µ–Ω–∏—è–º")
				st.write("NDCG:",result_2)
				st.write("MAP:",mean_average_precision(final_model_rec, final_gold_standart))	
				st.write("MRR:",mean_reciprocal_rank(final_gold_standart))

				if result_2 >= 0.4:
					st.markdown("### –í–°–ï –•–û–†–û–®–û")
				else:
					st.markdown("### –ë–´–õ–û –ü–û–õ–£–ß–®–ï")


		elif options == '2':

			st.markdown("# –°–ø–æ—Å–æ–± –≤—Ç–æ—Ä–æ–π")
			st.markdown(desc_alg2,unsafe_allow_html=True)

			ans1, ans2 = st.columns(2)

			with ans1:
				final_model_rec = []
				final_gold_standart = []
				for offer_id in new_metrics:
					final_model_rec.append(metrics[offer_id])
					final_gold_standart.append(numbers_gs[offer_id])

				final = my_ndcg(final_model_rec, final_gold_standart)
				# sums = 0
				# expan_l = st.expander("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å DCG, MAX DCG")
				# with expan_l:
				# 	for i in range(len(final_model_rec)):
				# 		l = ndcg_at_k(final_model_rec[i], final_gold_standart[i], 10, 1)
				# 		sums += l
				st.write("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏–∑ –ó–æ–ª–æ—Ç–æ–≥–æ –°—Ç–∞–Ω–¥–∞—Ä—Ç–∞")
				# final = sums/len(final_model_rec)
				st.write('NDCG',final)

				if final >= 0.4:
					st.markdown("### –í–°–ï –•–û–†–û–®–û")
				else:
					st.markdown("### –ë–´–õ–û –ü–û–õ–£–ß–®–ï")


if __name__ == '__main__':
	try:
		main()
	finally:
		os.system('rm -rf *.csv')