from unittest import result
import streamlit as st
import pandas as pd
import numpy as np
import json
import copy
from sklearn.metrics import ndcg_score
###################################

from st_aggrid import AgGrid
from st_aggrid.grid_options_builder import GridOptionsBuilder
from st_aggrid.shared import JsCode
from description import desc_alg1, desc_alg2,desc_alg3
###################################

from functionforDownloadButtons import download_button
from crossale_utils import *
from first_algos import ndcg_at
from second_algos import ndcg_at_k

###################################


def _max_width_():
    max_width_str = f"max-width: 1800px;"
    st.markdown(
        f"""
    <style>
    .reportview-container .main .block-container{{
        {max_width_str}
    }}
    </style>    
    """,
        unsafe_allow_html=True,
    )

st.set_page_config(page_icon="‚úÇÔ∏è", page_title="CSV Wrangler")

st.image(
    "https://emojipedia-us.s3.dualstack.us-west-1.amazonaws.com/thumbs/240/apple/285/scissors_2702-fe0f.png",
    width=100,
)

c29, c30, c31 = st.columns([1, 6, 1])

with c30:

	number = st.slider('–°–∫–æ–ª—å–∫–æ –¥–∞—Ç–∞ —Ñ—Ä–µ–π–º–æ–≤ –Ω—É–∂–Ω–æ —Å–∫–ª–µ–∏—Ç—å?',1,5,key='database_count')
	all_db = None

	uploaded_file = st.file_uploader(
		"",
		key="1",
		help="To activate 'wide mode', go to the hamburger menu > Settings > turn on 'wide mode'",
	)

	if uploaded_file is not None:
		file_container = st.expander("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–∞—à –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª .csv")
		all_db = pd.read_csv(uploaded_file)
		uploaded_file.seek(0)
		file_container.write(all_db)
		if st.session_state['database_count'] != 1:

			for i in range(st.session_state['database_count'] - 1):
				uploaded_file = st.file_uploader(
					"",
					key=str(i+2),
				)

				if uploaded_file is not None:
					file_container = st.expander("–ü—Ä–æ–≤–µ—Ä—å—Ç–µ –≤–∞—à –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π —Ñ–∞–π–ª .csv")
					shows = pd.read_csv(uploaded_file,index_col='name')
					all_db = all_db.merge(shows, left_on="name",right_on="name")
					uploaded_file.seek(0)
					file_container.write(shows)
				else:
					st.stop()

	else:
		st.info(
			f"""
				üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ a .csv —Ñ–∞–π–ª. –ù–∞–ø—Ä–∏–º–µ—Ä: [biostats.csv](https://people.sc.fsu.edu/~jburkardt/data/csv/biostats.csv)
				"""
		)

		st.stop()

from st_aggrid import GridUpdateMode, DataReturnMode

gb = GridOptionsBuilder.from_dataframe(all_db)

gb.configure_default_column()
gb.configure_selection(selection_mode="multiple", use_checkbox=True)
gb.configure_side_bar()
gridOptions = gb.build()

st.success(
    f"""
        üí° –ü–æ–¥—Å–∫–∞–∑–∫–∞! –£–¥–µ—Ä–∂–∏–≤–∞–π—Ç–µ shift —á—Ç–æ–±—ã –≤—ã–±—Ä–∞—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫!
        """
)

response = AgGrid(
    all_db,
    gridOptions=gridOptions,
    enable_enterprise_modules=True,
    update_mode=GridUpdateMode.MODEL_CHANGED,
    data_return_mode=DataReturnMode.FILTERED_AND_SORTED,
    fit_columns_on_grid_load=False,
)



df = pd.DataFrame(response["selected_rows"])

try:
	df = df.set_index('name')
except:
	st.write("–í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω —Ç–æ–≤–∞—Ä")

st.subheader("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç üëá ")
st.text("")

but1, but2, _ = st.columns(3)

with but1:
	show_table = st.button("–ü–æ–∫–∞–∑–∞—Ç—å —Ç–∞–±–ª–∏—Ü—É")
with but2:
	hide_table = st.button("–°–∫—Ä—ã—Ç—å —Ç–∞–±–ª–∏—Ü—É")

if show_table:
	st.table(df)

	c29, c30, c31 = st.columns([1, 1, 2])

	with c29:

		CSVButton = download_button(
			df,
			"File.csv",
			"Download to CSV",
		)

	with c30:
		CSVButton = download_button(
			df,
			"File.csv",
			"Download to TXT",
		)
	st.stop()



st.text("")

st.write("–ó–∞–≥—Ä—É–∑–∏—Ç–µ JSON")

json_file = st.file_uploader(
		"",
		key="json",
	)

if json_file is not None:
	js = json.load(json_file)

else:
	st.info(
		f"""
			üëÜ –ó–∞–≥—Ä—É–∑–∏—Ç–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –∫–∞—Ç–∞–ª–æ–≥ —Å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è–º–∏ –≤ —Ñ–æ—Ä–º–∞—Ç–µ json
			"""
	)

	st.stop()

model_recommendation = {} # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –º–æ–¥–µ–ª–∏
gold_standart = {} # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –ø–æ –∑–æ–ª–æ—Ç–æ–º—É —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É
numbers_gs = {} # –°–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ –æ—Ü–µ–Ω–æ–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –ø–æ –∑–æ–ª–æ—Ç–æ–º—É —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É

new_data = df

all_trimmer = new_data.index #url –≤—Å–µ—Ö —Ç—Ä–∏–º–º–µ—Ä–æ–≤
all_rec = new_data.columns #–Ω–∞–∑–≤–∞–Ω–∏—è –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤ –¥–ª—è –∫—Ä–æ—Å—Å-—Å–µ–π–ª–∞

#–∑–∞–ø—É—Å–∫–∞–µ–º —Ü–∏–∫–ª –ø–æ –î–∞—Ç–∞–§—Ä–µ–π–º—É
for url in all_trimmer:
	gold_standart_pair = {}
	numbers_gs_mass = []

	one_line = new_data.loc[url]
	for name_rec in all_rec:
		gold_standart_pair[name_rec.strip()]=new_data[name_rec][url]/100 # –ó–∞—Å–æ–≤—ã–≤–∞–µ–º –Ω–∞–∑–≤–∞–Ω–∏–µ –∏ –æ—Ü–µ–Ω–∫—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –≤ —Å–ª–æ–≤–∞—Ä—å
		numbers_gs_mass.append(new_data[name_rec][url]/100)

	offer_id = return_id(url) # –≤—ã—Ä–µ–∑–∞–µ–º offer_id –∏–∑ —Å—Å—ã–ª–∫–∏ 
	numbers_gs_mass.sort(reverse=True) # —Å–æ—Ä—Ç–∏—Ä—É–µ–º –≤—Å–µ —ç–ª–µ–º–µ–Ω—Ç—ã –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é
	gold_standart[offer_id] = gold_standart_pair # –ó–∞—Å–æ–≤—ã–≤–∞–µ–º –ø–æ offer_id —Å–ª–æ–≤–∞—Ä—å —Å –æ—Ü–µ–Ω–∫–æ–π —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Ç–æ–≤–∞—Ä–æ–≤
	numbers_gs[offer_id] = numbers_gs_mass

json_elem = js["recommendations"]
# –ù–∞—Ö–æ–¥–∏–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–æ–≤–∞—Ä–∞
for elem in json_elem:
	model_recommendation_mass = []
	url_json_elem = return_id(elem['urlLink'])
	mass_rec_id = elem["recommendItems"]
	
	for offer_id in mass_rec_id:
		model_recommendation_mass.append(offer_id['name'])
	model_recommendation[url_json_elem] = model_recommendation_mass

#–í—ã–¥–∞–µ–º –≤—Å–µ–º —Ç–æ–≤–∞—Ä–∞–º –∏–∑ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ JSON –æ—Ü–µ–Ω–∫—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏–∑ –ó–æ–ª–æ—Ç–æ–≥–æ –°—Ç–∞–Ω–¥–∞—Ä—Ç–∞
metrics = {} # —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –æ—Ü–µ–Ω–∫–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∫ –∫–∞–∂–¥–æ–º—É —Ç–æ–≤–∞—Ä—É 
metrics_name = {} # —Å–ª–æ–≤–∞—Ä—å –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞–∑–≤–∞–Ω–∏–π —Ç–æ–≤–∞—Ä–æ–≤

for offer_id, rec_mass in model_recommendation.items():
	metrics_dic = []
	names = []
	for product in rec_mass:
			zz = 0
			try:
				metrics_dic.append(gold_standart[offer_id][product])
				names.append(product)
			except:
				q = 0
	if metrics_dic:
		metrics[offer_id] = metrics_dic
	if names:
		metrics_name[offer_id] = names

but3, but4, _  = st.columns(3)

with but3:
	show_rec = st.button("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")
with but4:
	hide_rec = st.button("–°–∫—Ä—ã—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏")


#–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –Ω–∞–≥–ª—è–¥–Ω–æ —á—Ç–æ –ø—Ä–µ–¥–ª–∞–≥–∞–µ—Ç –º–æ–¥–µ–ª—å –∏ –∑–æ–ª–æ—Ç–æ–π —Å—Ç–∞–Ω–¥–∞—Ä—Ç
if show_rec:
	st.markdown('<h2 style="font-size:24px;">–¢–û–ü 10 –¢–û–í–ê–†–û–í –î–õ–Ø –¢–†–ò–ú–ú–ï–†–ê</h2>', unsafe_allow_html=True)
	new_metrics, name_gs = print_top5(metrics, metrics_name, gold_standart)

new_metrics, name_gs = print_top5(metrics, metrics_name, gold_standart, print_=False)


windows = st.number_input("–ó–∞–¥–∞—Ç—å –æ–∫–æ—à–∫–æ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏", key="win1_r",value=3,step=1,
help="–û–∫–æ—à–∫–æ –≤–∞–ª–∏–¥–Ω–æ—Å—Ç–∏ - –¥–æ–ø—É—Å—Ç–∏–º–∞—è –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å –≤ –ø–æ—Ä—è–¥–∫–µ —Ç–æ–≤–∞—Ä–∞ –≤ –ª–µ–Ω—Ç–µ. –ù–∞–ø—Ä–∏–º–µ—Ä: \n\
	[1,3,4,5,6,7] –ø—Ä–∏ –æ–∫–æ—à–∫–µ 3 —Ç–æ–≤–∞—Ä –ø–æ–¥ –Ω–æ–º–µ—Ä–æ–º 4 –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–∞ 2,3,4 –º–µ—Å—Ç–∞—Ö")
options = st.radio("–í—ã–±–µ—Ä–∏—Ç–µ –∞–ª–≥–æ—Ä–∏—Ç–º", ['1', '2', '3'], key='algorithm_radio')
windows //= 2
go_button = st.button('–ü–æ–¥—Å—á–∏—Ç–∞—Ç—å')

if go_button:

	if options == '1':

		st.markdown("# –°–ø–æ—Å–æ–± –ø–µ—Ä–≤—ã–π")
		st.markdown(desc_alg1,unsafe_allow_html=True)

		ans1, ans2 = st.columns(2)

		with ans1:
			final_gold_standart, final_model_rec = valid_product(metrics_name, name_gs, copy.deepcopy(metrics), windows)
			expan_l = st.expander("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å DCG, MAX DCG")
			with expan_l:
				result_1 = ndcg_at(final_model_rec, final_gold_standart)
			st.write("C—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –∏–º–µ–Ω–∞–º")
			st.write(result_1)

		with ans2:
			final_gold_standart, final_model_rec = valid_product_value(metrics, numbers_gs, copy.deepcopy(metrics), windows)
			expan_r = st.expander("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å DCG, MAX DCG")
			with expan_r:
				result_2 = ndcg_at(final_model_rec, final_gold_standart)
			st.write("C—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –∑–Ω–∞—á–µ–Ω–∏—è–º")
			st.write("–ò—Ç–æ–≥:",result_2)

	elif options == '2':

		st.markdown("# –°–ø–æ—Å–æ–± –≤—Ç–æ—Ä–æ–π")
		st.markdown(desc_alg2,unsafe_allow_html=True)

		ans1, ans2 = st.columns(2)

		with ans1:
			final_model_rec = []
			final_gold_standart = []
			for offer_id in new_metrics:
				final_model_rec.append(metrics[offer_id])
				final_gold_standart.append(numbers_gs[offer_id])

			sums = 0
			expan_l = st.expander("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å DCG, MAX DCG")
			with expan_l:
				for i in range(len(final_model_rec)):
					l = ndcg_at_k(final_model_rec[i], final_gold_standart[i], 10, 1)
					sums += l
			st.write("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ –∏–∑ –ó–æ–ª–æ—Ç–æ–≥–æ –°—Ç–∞–Ω–¥–∞—Ä—Ç–∞")
			st.write(sums/len(final_model_rec))

		with ans2:
			m = metrics.copy()
			final_model_rec = []
			final_gold_standart = []
			for met in metrics_name:
				gs_mini = []
				for i in range(len(metrics_name[met])):
					if i < windows:
						mini = 0
					else:
						mini = i - windows
					if i + windows > len(metrics_name[met]):
						maxs = len(metrics_name[met])
					else:
						maxs = i + windows
					if metrics_name[met][i] == name_gs[met][i]:
						m[met][i] = 3
					elif metrics_name[met][i] in name_gs[met][mini:maxs]:
						m[met][i] = 2
					elif metrics_name[met][i] in name_gs[met]:
						m[met][i] = 1
					else:
						m[met][i] = 0
					gs_mini.append(3)
				final_gold_standart.append(gs_mini)
				final_model_rec.append(m[met])

			sums = 0
			expan_r = st.expander("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å DCG, MAX DCG")

			with expan_r:
				for i in range(len(final_model_rec)):
					l = ndcg_at_k(final_model_rec[i], final_gold_standart[i], 10, 1)
					sums += l
			st.write("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –≤–µ—Å–∞–º")
			st.write(sums/len(final_model_rec))

	elif options == '3':

		st.markdown("# –°–ø–æ—Å–æ–± —Ç—Ä–µ—Ç–∏–π")
		st.markdown(desc_alg3,unsafe_allow_html=True)

		final_model_rec = []
		final_gold_standart = []
		for offer_id in new_metrics:
			final_model_rec.append(metrics[offer_id])
			final_gold_standart.append(numbers_gs[offer_id])
		summ = 0
		for i in range(len(final_model_rec)):
			true_relevanse = np.asarray([final_model_rec[i]])
			score = np.asarray([final_gold_standart[i][:len(final_model_rec[i])]])
			if len(final_model_rec[i]) > 1:
				summ += ndcg_score(true_relevanse,score, k=10)
		st.write(summ/len(final_model_rec))